<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>视觉算法 on 古月月仔的博客</title>
    <link>http://localhost:1313/tags/%E8%A7%86%E8%A7%89%E7%AE%97%E6%B3%95/</link>
    <description>Recent content in 视觉算法 on 古月月仔的博客</description>
    <generator>Hugo</generator>
    <language>zh-cn</language>
    <lastBuildDate>Tue, 31 Dec 2024 00:00:00 +0800</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/%E8%A7%86%E8%A7%89%E7%AE%97%E6%B3%95/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>【OpenPCDet】PointPillar算法思路</title>
      <link>http://localhost:1313/posts/openpcdetpointpillar%E7%AE%97%E6%B3%95%E6%80%9D%E8%B7%AF/</link>
      <pubDate>Tue, 31 Dec 2024 00:00:00 +0800</pubDate>
      <guid>http://localhost:1313/posts/openpcdetpointpillar%E7%AE%97%E6%B3%95%E6%80%9D%E8%B7%AF/</guid>
      <description>&lt;p&gt;PointPillar 是一种用于三维物体检测的深度学习模型，尤其适用于激光雷达点云数据的处理。它的设计思想相对简洁，并且在保持高效性的同时能获得较高的精度。&#xA;&lt;a href=&#34;https://arxiv.org/abs/1812.05784&#34; target=&#34;_blank&#34;&gt;论文地址&lt;/a&gt;&#xA;&#xA;&lt;a href=&#34;https://link.zhihu.com/?target=https%3A//github.com/SmallMunich/nutonomy_pointpillars&#34; target=&#34;_blank&#34;&gt;代码地址&lt;/a&gt;&#xA;&lt;/p&gt;&#xA;&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;&#xA;&lt;p&gt;本文要解析的模型叫做&lt;a href=&#34;https://zhida.zhihu.com/search?content_id=167602095&amp;amp;content_type=Article&amp;amp;match_order=1&amp;amp;q=PointPillars&amp;amp;zhida_source=entity&#34; target=&#34;_blank&#34;&gt;PointPillars&lt;/a&gt;&#xA;，是2019年出自工业界的一篇Paper。&#xA;该模型最主要的特点是&lt;strong&gt;检测速度和精度的平衡&lt;/strong&gt;。该模型的平均检测速度达到了62Hz，最快速度达到了105Hz，确实遥遥领先了其他的模型。这里我们引入&lt;a href=&#34;https://zhida.zhihu.com/search?content_id=167602095&amp;amp;content_type=Article&amp;amp;match_order=1&amp;amp;q=CIA-SSD&amp;amp;zhida_source=entity&#34; target=&#34;_blank&#34;&gt;CIA-SSD&lt;/a&gt;&#xA;&lt;strong&gt;模型中的精度-速度图&lt;/strong&gt;，具体对比如下所示。&#xA;&lt;figure style=&#34;text-align: center; margin: 1.5rem auto;&#34;&gt;&#xA;  &#xA;  &lt;img src=&#34;https://github.com/user-attachments/assets/2b4acd80-8c42-4b92-a8ee-34f9be41f0b4&#34; &#xA;       alt=&#34;Image&#34; &#xA;       &#xA;       class=&#34;zoomable&#34; &#xA;       style=&#34;max-width: 100%; height: auto; border-radius: 8px; cursor: zoom-in;&#34;&#xA;       loading=&#34;lazy&#34; /&gt;&#xA;  &#xA;    &lt;figcaption style=&#34;margin-top: 8px; font-size: 0.85em; color: #888; font-style: italic;&#34;&gt;&#xA;      Image&#xA;    &lt;/figcaption&gt;&#xA;  &#xA;&lt;/figure&gt;&#xA;截止CIA-SSD论文发表前，PointPillars的检测速度都是遥遥领先的，而且精度也不低。&#xA;现有的一些研究喜欢将不规则、稀疏的点云数据按照以下两种方式进行处理，然后引入RPN层进行3D Bbox Proposal，这两种方法为：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;一种是将点云数据划纳入一个个&lt;strong&gt;体素（Voxel）&lt;strong&gt;中，构成规则的、密集分布的体素集。常见的有&lt;/strong&gt;VoxelNet&lt;/strong&gt;和&lt;strong&gt;SECOND&lt;/strong&gt;；&lt;/li&gt;&#xA;&lt;li&gt;另一种从&lt;strong&gt;俯视角度&lt;/strong&gt;将点云数据进行处理，获得一个个&lt;strong&gt;伪图片&lt;/strong&gt;的数据。常见的模型有&lt;strong&gt;MV3D和AVOD&lt;/strong&gt;。&#xA;PointPillar模型采用了一种不同于上述两种思路的点云建模方法。从模型的名称PointPillars可以看出，该方法将Point转化成一个个的&lt;strong&gt;Pillar（柱体）&lt;/strong&gt;，从而构成了&lt;strong&gt;伪图片&lt;/strong&gt;的数据。&#xA;然后对伪图片数据进行&lt;strong&gt;BBox Proposal&lt;/strong&gt;就很简单了，作者采用了&lt;strong&gt;SSD&lt;/strong&gt;的网络结构进行了Proposal。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;数据处理&#34;&gt;数据处理&lt;/h2&gt;&#xA;&lt;p&gt;PointPillar的一大亮点是将点云划分为一个个的Pillar，从而构成了伪图片的数据。&#xA;如何构成这个伪图片呢？作者在论文中是给出了这样的图，如下。&#xA;&lt;figure style=&#34;text-align: center; margin: 1.5rem auto;&#34;&gt;&#xA;  &#xA;  &lt;img src=&#34;https://github.com/user-attachments/assets/24ae971c-0384-4019-897b-37a988259979&#34; &#xA;       alt=&#34;Image&#34; &#xA;       &#xA;       class=&#34;zoomable&#34; &#xA;       style=&#34;max-width: 100%; height: auto; border-radius: 8px; cursor: zoom-in;&#34;&#xA;       loading=&#34;lazy&#34; /&gt;&#xA;  &#xA;    &lt;figcaption style=&#34;margin-top: 8px; font-size: 0.85em; color: #888; font-style: italic;&#34;&gt;&#xA;      Image&#xA;    &lt;/figcaption&gt;&#xA;  &#xA;&lt;/figure&gt;&#xA;具体实现步骤如下：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;按照点云数据所在的X，Y轴（不考虑Z轴）将点云数据划分为&lt;strong&gt;一个个的网格&lt;/strong&gt;，凡是落入到一个网格的点云数据被视为其处在&lt;strong&gt;一个pillar&lt;/strong&gt;里，或者理解为它们构成了一个Pillar。&lt;/li&gt;&#xA;&lt;li&gt;每个点云用一个 $ D=9$ 维的向量表示，分别为 $(x,y,z,r,x_c,y_c,z_c,x_p,y_p)$。其中 $(x,y,z,r)$ 为该点云的真实坐标信息（三维）和反射强度（注在openpcdet的代码实现中是10维，多了一个zp，也就是该点在z轴上与该点所处pillar的z轴中心的偏移量）. $(x_c,y_c,z_c)$ 为该点云所处Pillar中所有点的几何中心; $x_p$ , $y_p$ 为 $x-x_c$ , $y-y_c$ ,反应了点与几何中心的&lt;strong&gt;相对位置&lt;/strong&gt;。&lt;/li&gt;&#xA;&lt;li&gt;假设每个样本中有 $P$ 个非空的pillars，每个pillar中有 $N$ 个点云数据，那么这个样本就可以用一个 $(D,P,N)$ 张量表示。&#xA;那么可能就有人问了，怎么保证每个pillar中有 $N$ 个点云数据呢？&#xA;如果每个pillar中的点云数据数据超过 $N$ 个，那么我们就随机采样至 $N$ 个；如果每个pillar中的点云数据数据少于 $N$ 个，少于的部分我们就填充为0；这样就实现了点云数据的张量化，具体过程如下图所示&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;figure style=&#34;text-align: center; margin: 1.5rem auto;&#34;&gt;&#xA;  &#xA;  &lt;img src=&#34;https://github.com/user-attachments/assets/d66b3bbb-0681-4947-b1a6-a997bd14ed40&#34; &#xA;       alt=&#34;Image&#34; &#xA;       &#xA;       class=&#34;zoomable&#34; &#xA;       style=&#34;max-width: 100%; height: auto; border-radius: 8px; cursor: zoom-in;&#34;&#xA;       loading=&#34;lazy&#34; /&gt;&#xA;  &#xA;    &lt;figcaption style=&#34;margin-top: 8px; font-size: 0.85em; color: #888; font-style: italic;&#34;&gt;&#xA;      Image&#xA;    &lt;/figcaption&gt;&#xA;  &#xA;&lt;/figure&gt;&#xA;实现张量化后，作者利用简化版本的PointNet对张量化的点云数据进行处理和特征提取。&#xA;特征提取可以理解为对点云的维度进行处理，原来的点云维度为  $D=9$  ,处理后的维度为 $C$ ,那么我们就获得了一个 $(C,P,N)$ 的张量。&#xA;接着，我们按照Pillar所在维度进行Max Pooling操作，即获得了 $(C,P)$ 维度的特征图。&#xA;为了获得伪图片特征，作者将 $ P$ 转换为 $(H,W)$ ,即 $P-&gt;H*W$ .那么我们就获得了形如 $(C,H,W)$ 的伪图片了。具体过程如下：&#xA;&lt;figure style=&#34;text-align: center; margin: 1.5rem auto;&#34;&gt;&#xA;  &#xA;  &lt;img src=&#34;https://github.com/user-attachments/assets/5d8d4957-d83a-43b1-8a67-7b45fd05fb12&#34; &#xA;       alt=&#34;Image&#34; &#xA;       &#xA;       class=&#34;zoomable&#34; &#xA;       style=&#34;max-width: 100%; height: auto; border-radius: 8px; cursor: zoom-in;&#34;&#xA;       loading=&#34;lazy&#34; /&gt;&#xA;  &#xA;    &lt;figcaption style=&#34;margin-top: 8px; font-size: 0.85em; color: #888; font-style: italic;&#34;&gt;&#xA;      Image&#xA;    &lt;/figcaption&gt;&#xA;  &#xA;&lt;/figure&gt;&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
