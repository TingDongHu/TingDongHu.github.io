<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>CV on 古月月仔的博客</title>
    <link>http://localhost:1313/tags/cv/</link>
    <description>Recent content in CV on 古月月仔的博客</description>
    <generator>Hugo</generator>
    <language>zh-cn</language>
    <lastBuildDate>Sat, 30 Nov 2024 00:00:00 +0800</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/cv/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>【OpenPCDet】Uncertainty Estimation学习笔记（一）</title>
      <link>http://localhost:1313/posts/openpcdetuncertainty-estimation%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B8%80/</link>
      <pubDate>Sat, 30 Nov 2024 00:00:00 +0800</pubDate>
      <guid>http://localhost:1313/posts/openpcdetuncertainty-estimation%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B8%80/</guid>
      <description>&lt;h2 id=&#34;为什么要研究uncertainty&#34;&gt;为什么要研究uncertainty？&lt;/h2&gt;&#xA;&lt;p&gt;训练好的[神经网络模型本质是一个拥有大量确定参数的函数，不管你给什么输入，它都能给你一个输出。这会导致两种我们不愿意看到的意外情况：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;对明明错误的预测结果，模型输出的[置信度]却很高&lt;/li&gt;&#xA;&lt;li&gt;对没有见过的输入(OoD，Out-of-ditribution)，比如给一个识别猫/狗的模型输入一张桌子图片，模型一定会输出：”这是猫“ or “这是狗”，而不是告诉我们 “它似乎不是猫，也不是狗”&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;所以，我们希望模型能输出 uncertainty，辅助使用模型的人进行更好地决策。比如上面的例子中，我们希望对错误分类的样本、OoD样本，模型能够给出一个较高的uncertainty。&lt;/p&gt;&#xA;&lt;h2 id=&#34;uncertainy是什么&#34;&gt;uncertainy是什么？&lt;/h2&gt;&#xA;&lt;p&gt;参考NIPS2017年的论文 &lt;a href=&#34;https://link.zhihu.com/?target=https%3A//papers.nips.cc/paper/7141-what-uncertainties-do-we-need-in-bayesian-deep-learning-for-computer-vision.pdf&#34; target=&#34;_blank&#34;&gt;What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision? &lt;/a&gt;&#xA;，Gal阐述了两种uncertainty：Aleatoric uncertainty(i.e. data uncertainty) 和 Epistemic uncertainty(i.e. model uncertainty)，即随机不确定度(也称数据不确定度)，和认知不确定度(也称模型不确定度)。&lt;/p&gt;&#xA;&lt;p&gt;Epistemic uncertainty可以通过增加数据解决，比如下图：只有一个data point的时候，符合要求的模型有很多种可能，uncertainty很高。当数据点增加，模型逐渐确定，uncertainty减小。&#xA;&lt;figure style=&#34;text-align: center; margin: 1.5rem auto;&#34;&gt;&#xA;  &#xA;  &lt;img src=&#34;https://github.com/user-attachments/assets/82e8de7c-1ac8-4cbe-82c1-417cf2299c3c&#34; &#xA;       alt=&#34;image&#34; &#xA;       &#xA;       class=&#34;zoomable&#34; &#xA;       style=&#34;max-width: 100%; height: auto; border-radius: 8px; cursor: zoom-in;&#34;&#xA;       loading=&#34;lazy&#34; /&gt;&#xA;  &#xA;    &lt;figcaption style=&#34;margin-top: 8px; font-size: 0.85em; color: #888; font-style: italic;&#34;&gt;&#xA;      image&#xA;    &lt;/figcaption&gt;&#xA;  &#xA;&lt;/figure&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;how怎么计算不确定度&#34;&gt;How？怎么计算不确定度&lt;/h2&gt;&#xA;&lt;h3 id=&#34;1epistemic-uncertainty建模&#34;&gt;1.Epistemic uncertainty建模&lt;/h3&gt;&#xA;&lt;p&gt;&lt;figure style=&#34;text-align: center; margin: 1.5rem auto;&#34;&gt;&#xA;  &#xA;  &lt;img src=&#34;https://github.com/user-attachments/assets/0a9ea3a7-f202-4c11-919d-b599aed777dd&#34; &#xA;       alt=&#34;image&#34; &#xA;       &#xA;       class=&#34;zoomable&#34; &#xA;       style=&#34;max-width: 100%; height: auto; border-radius: 8px; cursor: zoom-in;&#34;&#xA;       loading=&#34;lazy&#34; /&gt;&#xA;  &#xA;    &lt;figcaption style=&#34;margin-top: 8px; font-size: 0.85em; color: #888; font-style: italic;&#34;&gt;&#xA;      image&#xA;    &lt;/figcaption&gt;&#xA;  &#xA;&lt;/figure&gt;&#xA;Monte-Carlo 和 Ensemble&#xA;对一个随机分布，不确定性建模的方法有很多，标准差、方差、风险值（VaR）和熵都是合适的度量。在深度学习中，建模不确定度需要用到Bayesian DeepLearning。从Bayesian的角度，深度学习训练的本质是求一个posterior distribution  $P(W|D)$ ，其中W是参数，D是数据。根据bayes theorem（贝叶斯定理），我们有 $P(W|D)=\frac{P(D|W)P(W)}{P(D)}$&#xA;但是这个公式没法用，因为 $P(D)$ 理论上代表的是真实的数据分布，无法获取; $P(W)$ 在神经网络中也是不存在的，因为模型训练好以后，所有参数都是确定的数，而不是distribution，没法计算 $P(W)$ 。于是我们想到bayes theorem的另一个公式: $P(D)=\sum_i{P(D|W_i)P(W_i)}$&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
